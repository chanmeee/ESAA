{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 모델 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 패키지 설치 / 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed 고정 \n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiwon\n"
     ]
    }
   ],
   "source": [
    "# 현재 디렉토리 확인 \n",
    "import os\n",
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiwon\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (5,8,11,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 불러온다. \n",
    "trn = pd.read_csv('C:/Users/jiwon/data/train_ver2.csv') # 다운 받은 파일이 해당 경로에 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiwon\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "tst = pd.read_csv('C:/Users/jiwon/data/test_ver2.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제품 변수를 별도로 저장해 놓는다.\n",
    "prods = trn.columns[24:].tolist()\n",
    "\n",
    "# 제품 변수 결측값을 미리 0으로 대체한다.\n",
    "trn[prods] = trn[prods].fillna(0.0).astype(np.int8)\n",
    "\n",
    "# 24개 제품 중 하나도 보유하지 않는 고객 데이터를 제거한다.\n",
    "no_product = trn[prods].sum(axis=1) == 0  # axis=1은 y축 합계 \n",
    "trn = trn[~no_product]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터를 통합한다. 테스트 데이터에 없는 제품 변수는 0으로 채운다.\n",
    "for col in trn.columns[24:]:\n",
    "    tst[col] = 0\n",
    "df = pd.concat([trn, tst], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용할 변수를 담는 list이다.\n",
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수를 .factorize() 함수를 통해 label encoding한다.\n",
    "categorical_cols = ['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento']\n",
    "for col in categorical_cols:\n",
    "    df[col], _ = df[col].factorize(na_sentinel=-99)  # na_sentinel은 missing value가 -99로 표현되도록 만든다. 이때 -99는 unique한 값으로 여겨지지 않는다. \n",
    "features += categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 -1  1  2  0]\n",
      "['b' 'a' 'c']\n"
     ]
    }
   ],
   "source": [
    "## 참고: na_sentinel\n",
    "codes, uniques = pd.factorize(['b', None, 'a', 'c', 'b'])\n",
    "print(codes)\n",
    "print(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 변수의 특이값과 결측값을 -99로 대체하고, 정수형으로 변환한다.\n",
    "df['age'].replace(' NA', -99, inplace=True)\n",
    "df['age'] = df['age'].astype(np.int8)\n",
    "\n",
    "df['antiguedad'].replace('     NA', -99, inplace=True)\n",
    "df['antiguedad'] = df['antiguedad'].astype(np.int8)\n",
    "\n",
    "df['renta'].replace('         NA', -99, inplace=True)\n",
    "df['renta'].fillna(-99, inplace=True)\n",
    "df['renta'] = df['renta'].astype(float).astype(np.int8)\n",
    "\n",
    "df['indrel_1mes'].replace('P', 5, inplace=True)  # 고객 구분이 1,2,3,4,P등급으로 되어있는데, 여기서 P등급을 5로 바꾸어 줌 \n",
    "df['indrel_1mes'].fillna(-99, inplace=True)\n",
    "df['indrel_1mes'] = df['indrel_1mes'].astype(float).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용할 수치형 변수를 features에 추구한다.\n",
    "features += ['age','antiguedad','renta','ind_nuevo','indrel','indrel_1mes','ind_actividad_cliente'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 피쳐 엔지니어링 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "피쳐 엔지니어링 단계에서는 모델 학습에 사용한 파생 변수를 생성한다.\n",
    "ex) 날짜/시간 정보 → 주중/주말 여부, 공휴일 여부, 아침/낮/밤, 봄/여름/가을/겨울 등 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline 모델에서는 전체 24개의 고객 변수와, 4개의 날짜 변수 기반 파생 변수, 그리고 24개의 lag-1 변수를 사용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 날짜 변수 기반 파생 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개의 날짜 변수에서 연도와 월 정보를 추출한다.\n",
    "# fecha_alta_month(고객이 첫 계약을 맺은 날짜), ult_fec_cli_1t_month(고객이 마지막으로 1등급이었던 날짜)\n",
    "\n",
    "# fetcha_alta 변수형이 float(실수)이면 0을 반환하고, 아닐 경우 '-'를 기준으로 나누어 2번째 값을 정수형으로 표현한 뒤, fetcha_alta_month로 저장 \n",
    "df['fecha_alta_month'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8) \n",
    "df['fecha_alta_year'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "features += ['fecha_alta_month', 'fecha_alta_year']\n",
    "\n",
    "df['ult_fec_cli_1t_month'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['ult_fec_cli_1t_year'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "features += ['ult_fec_cli_1t_month', 'ult_fec_cli_1t_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*참고: 데이터 효율을 위해 month와 year을 각각 int8과 int16으로 표현한 것으로 보인다. int8과 int16는 각각 2^8개, 2^16개의 정수 표현이 가능하다. 즉, 각각 -128부터 127까지, -32768부터 32767까지의 정수를 표현할 수 있다. 범위가 1부터 12까지인 월을 표현할 때는 int8로 충분히 표현이 가능하지만(int16을 사용하여 메모리를 불필요하게 많이 쓰지 않아도 됨), 연도는 네 자리 수이기 때문에 int16을 사용하여 정수로 변환한 것으로 보인다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이외에도 날짜 변수를 활용하여 다양한 파생 변수를 생성할 수 있다. 예를 들어 두 개의 날짜 변수 간의 차이값을 파생 변수를 생성한다거나, 졸업식이나 방학 등의 특별한 날짜까지의 거리를 수치형 변수로 생성할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결측값 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그 외 변수의 결측값은 모두 -99로 대체한다.\n",
    "df.fillna(-99, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런에서 제공하는 머신러닝 모델은 결측값을 입력값으로 받지 않고 실행 에러가 발생한다. 하지만 xgboost 모델에서는 결측값도 하나의 정보로 인식하고 모델 학습에 활용한다. 그러나 저자는 결측값을 -99로 설정함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lag-1 파생 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시계열 데이터라는 데이터 특성을 살려 고객의 과거 데이터를 기반으로 다양한 파생 변수를 생성할 수 있다. 예를 들어, 고객의 나이가 최근 3개월 동안 변동이 있었는지(즉, 3개월 안에 생일을 맞이했는지)를 이진 변수로 생성하거나, 한 달 전에 구매한 제품에 대한 정보를 변수로 사용할 수 있고, 최근 6개월 간 평균 월급을 계산할 수도 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "산탄데르 제품 추천 경진대회에서는 N개월 전에 금융 제품을 보유하고 있었는지 여부를 나타내는 lag 변수가 좋은 파생 변수로 작용했다. Baseline 모델에서는 1개월 전 정보만을 가져다 사용하는 lag-1 변수를 사용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜를 숫자로 변환하는 함수를 생성한다. 2015-01-28은 1, 2016-06-28은 18로 변환된다\n",
    "def date_to_int(str_date):\n",
    "    Y, M, D = [int(a) for a in str_date.strip().split(\"-\")]  # '-' 기준으로 날짜를 나눈 뒤 리스트 형태로 각각 Y, M, D에 저장 \n",
    "    int_date = (int(Y) - 2015) * 12 + int(M)  # 2015년 기준 개월 수를 계산 \n",
    "    return int_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜를 숫자로 변환하여 int_date에 저장한다\n",
    "df['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 복사하고, int_date 날짜에 1을 더하여 lag를 생성한다. ncodpers과 int_date를 제외한 변수명에 _prev를 추가한다.\n",
    "df_lag = df.copy()\n",
    "df_lag.columns = [col + '_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns ]\n",
    "df_lag['int_date'] += 1  # 만일 lag-2, lag-5를 만들고 싶다면, 여기에 있는 숫자를 2나 5로 바꾸면 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>fecha_alta</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>indrel</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_valo_fin_ult1</th>\n",
       "      <th>ind_viv_fin_ult1</th>\n",
       "      <th>ind_nomina_ult1</th>\n",
       "      <th>ind_nom_pens_ult1</th>\n",
       "      <th>ind_recibo_ult1</th>\n",
       "      <th>fecha_alta_month</th>\n",
       "      <th>fecha_alta_year</th>\n",
       "      <th>ult_fec_cli_1t_month</th>\n",
       "      <th>ult_fec_cli_1t_year</th>\n",
       "      <th>int_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1375586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fecha_dato  ncodpers  ind_empleado  pais_residencia  sexo  age  fecha_alta  \\\n",
       "0  2015-01-28   1375586             0                0     0   35  2015-01-12   \n",
       "1  2015-01-28   1050611             0                0     1   23  2012-08-10   \n",
       "\n",
       "   ind_nuevo  antiguedad  indrel  ... ind_valo_fin_ult1  ind_viv_fin_ult1  \\\n",
       "0        0.0           6     1.0  ...                 0                 0   \n",
       "1        0.0          35     1.0  ...                 0                 0   \n",
       "\n",
       "   ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  fecha_alta_month  \\\n",
       "0                0                  0                0                 1   \n",
       "1                0                  0                0                 8   \n",
       "\n",
       "   fecha_alta_year  ult_fec_cli_1t_month  ult_fec_cli_1t_year  int_date  \n",
       "0             2015                     0                    0         1  \n",
       "1             2012                     0                    0         1  \n",
       "\n",
       "[2 rows x 53 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato_prev</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado_prev</th>\n",
       "      <th>pais_residencia_prev</th>\n",
       "      <th>sexo_prev</th>\n",
       "      <th>age_prev</th>\n",
       "      <th>fecha_alta_prev</th>\n",
       "      <th>ind_nuevo_prev</th>\n",
       "      <th>antiguedad_prev</th>\n",
       "      <th>indrel_prev</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_valo_fin_ult1_prev</th>\n",
       "      <th>ind_viv_fin_ult1_prev</th>\n",
       "      <th>ind_nomina_ult1_prev</th>\n",
       "      <th>ind_nom_pens_ult1_prev</th>\n",
       "      <th>ind_recibo_ult1_prev</th>\n",
       "      <th>fecha_alta_month_prev</th>\n",
       "      <th>fecha_alta_year_prev</th>\n",
       "      <th>ult_fec_cli_1t_month_prev</th>\n",
       "      <th>ult_fec_cli_1t_year_prev</th>\n",
       "      <th>int_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1375586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  fecha_dato_prev  ncodpers  ind_empleado_prev  pais_residencia_prev  \\\n",
       "0      2015-01-28   1375586                  0                     0   \n",
       "1      2015-01-28   1050611                  0                     0   \n",
       "\n",
       "   sexo_prev  age_prev fecha_alta_prev  ind_nuevo_prev  antiguedad_prev  \\\n",
       "0          0        35      2015-01-12             0.0                6   \n",
       "1          1        23      2012-08-10             0.0               35   \n",
       "\n",
       "   indrel_prev  ... ind_valo_fin_ult1_prev  ind_viv_fin_ult1_prev  \\\n",
       "0          1.0  ...                      0                      0   \n",
       "1          1.0  ...                      0                      0   \n",
       "\n",
       "   ind_nomina_ult1_prev  ind_nom_pens_ult1_prev  ind_recibo_ult1_prev  \\\n",
       "0                     0                       0                     0   \n",
       "1                     0                       0                     0   \n",
       "\n",
       "   fecha_alta_month_prev  fecha_alta_year_prev  ult_fec_cli_1t_month_prev  \\\n",
       "0                      1                  2015                          0   \n",
       "1                      8                  2012                          0   \n",
       "\n",
       "   ult_fec_cli_1t_year_prev  int_date  \n",
       "0                         0         2  \n",
       "1                         0         2  \n",
       "\n",
       "[2 rows x 53 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lag.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어 날짜가 2015년 1월 28일이었다면 fecha_dato 변수에 들어간 값은 날짜형인 2015-01-28이었을 것이고, 이를 date_to_int 함수로 변환한 값인 1이 int_date에 저장된다. 그리고 _prev 변수에는 여기에 1인 더한 값인 2가 들어간다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fecha_dato였던 변수명이 fecha_dato_prev으로 바뀌었으며, 다른 변수들도 마찬가지이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터와 lag 데이터를 ncodper와 int_date 기준으로 합친다. Lag 데이터의 int_date는 1 밀려 있기 때문에, 저번 달의 제품 정보가 삽입된다.\n",
    "df_trn = df.merge(df_lag, on=['ncodpers','int_date'], how='left')\n",
    "\n",
    "# 이 명령어 실행시키는 데 시간이 오래 걸리니, 유의하세요. (저는 30분 정도 걸렸습니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 데이터셋을 합쳐 변수가 104개인 df_trn 데이터셋이 만들어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 효율을 위해 불필요한 변수를 메모리에서 제거한다\n",
    "del df, df_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저번 달의 제품 정보가 존재하지 않을 경우를 대비하여 0으로 대체한다.\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    df_trn[prev].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn.fillna(-99, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag-1 변수를 추가한다.\n",
    "features += [feature + '_prev' for feature in features]\n",
    "features += [prod + '_prev' for prod in prods]\n",
    "\n",
    "###\n",
    "### Baseline 모델 이후, 다양한 피쳐 엔지니어링을 여기에 추가한다.\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델 학습 및 예측\n",
    "\n",
    "#### 교차검증\n",
    "교차검증은 경진대회에서 좋은 성적을 거두기 위해 매우 중요. 올바른 교차 검증 과정을 통해 제한 없이 다양한 아이디어를 실험하고, 성능 개선 여부를 확인하는 것이 매우 중요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터: 2015-01-28 ~ 2016-05-28 (1년 6개월치) 테스트 데이터: 2018-06-28 (미래 데이터) --> 내부 교차검증 과정에서도 최신 데이터 (2016-05-28)를 검증 데이터로 분리, 나머지 데이터를 훈련 데이터로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 학습\n",
    "# 학습을 위하여 데이터를 훈련, 테스트용으로 분리한다.\n",
    "# 학습에는 2016-01-28 ~ 2016-04-28 데이터만 사용하고, 검증에는 2016-05-28 데이터를 사용한다.\n",
    "use_dates = ['2016-01-28', '2016-02-28', '2016-03-28', '2016-04-28', '2016-05-28']\n",
    "trn = df_trn[df_trn['fecha_dato'].isin(use_dates)] #isin 구문을 통해 use_dates 리스트 속 날짜들을 포함하고 있는 row만을 뽑아내 trn에 저장.\n",
    "tst = df_trn[df_trn['fecha_dato'] == '2016-06-28']\n",
    "del df_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터에서 신규 구매 건수만 추출한다.\n",
    "X = []\n",
    "Y = []\n",
    "for i, prod in enumerate(prods): #enumerate: 순서가 있는 자료형(리스트, 튜플, 문자열)을 입력받아 인덱스값에 포함시키는 역할\n",
    "    prev = prod + '_prev'\n",
    "    prX = trn[(trn[prod] == 1) & (trn[prev] == 0)]  #해당 시점 제품 보유 O & 한달 전 제품 보유 X 인 경우 즉 신규 제품 구매한 row만 뽑아낸다\n",
    "    prY = np.zeros(prX.shape[0], dtype=np.int8) + i #신규 구매에 대한 label 값\n",
    "    X.append(prX)\n",
    "    Y.append(prY)  \n",
    "XY = pd.concat(X) #Dataframe 형태로 만들어주는듯(?)\n",
    "Y = np.hstack(Y)\n",
    "XY['y'] = Y #XY는 신규 구매가 있었던 시점의 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련, 검증 데이터로 분리한다. \n",
    "vld_date = '2016-05-28'\n",
    "\n",
    "XY_trn = XY[XY['fecha_dato'] != vld_date] #훈련 데이터\n",
    "XY_vld = XY[XY['fecha_dato'] == vld_date] #검증 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용 모델: XGBoost\n",
    "eXtreme Gradient Boosting: \n",
    "\n",
    "- Gradient Boosting 알고리즘을 분산환경에서도 실행할 수 있도록 구현해놓은 라이브러리\n",
    "\n",
    "- 여러개의 Decision Tree를 조합해서 사용하는 앙상블 알고리즘\n",
    "\n",
    "- 구조화 되어있거나 표로 정리된 데이터셋에서 분류/회귀 에측모형을 만드는데 가장 많이 쓰임\n",
    "\n",
    "- 다른 Gradient Boosting 모델들에 비해 속도 매우 빠름\n",
    "\n",
    "- 모델 performance가 매우 좋음 (대부분의 캐글 상위 입상자들이 XGBoost 모델 사용) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost 모델의 파라미터\n",
    "- max_depth: 트리 모델의 최대 깊이. 값이 높을수록 더 복잡한 트리 모델 생성, 과적합의 원인이 될 수 있음.\n",
    "\n",
    "- eta: 딥러닝에서의 learning rate와 같은 개념. 0과 1 사이의 값을 가지며, 값이 너무 높으면 학습이 잘 되지 않을 수 있고 값이 너무 낮으면 학습이 느릴 수 있음.\n",
    "\n",
    "- colsample_bytree: 트리를 생성할 때 훈련 데이터에서 변수를 샘플링해주는 비율. 모든 트리는 전체 변수의 일부만을 학습하여 서로의 약점을 보완. 보통 0.6~0.9 사용.\n",
    "\n",
    "- colsample_bylevel: 트리의 레벨 별로 훈련 데이터의 변수를 샘플링해주는 비율. 보통 0.6~0.9 사용.\n",
    "\n",
    "\n",
    "*참고:\n",
    "모델의 파라미터 튜닝 작업에 너무 많은 시간을 투자하기 보다는 적당한 수준의 파라미터 튜닝 + 많은 시간을 피처 엔지니어링에 투자하여 양질의 변수를 얻자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 모델 parameter를 설정한다.\n",
    "param = {\n",
    "    'booster': 'gbtree',\n",
    "    'max_depth': 8,\n",
    "    'nthread': 4,\n",
    "    'num_class': len(prods),\n",
    "    'objective': 'multi:softprob',\n",
    "    'silent': 1,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'eta': 0.1,\n",
    "    'min_child_weight': 10,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'colsample_bylevel': 0.9,\n",
    "    'seed': 2018,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련, 검증 데이터를 XGBoost 형태로 변환한다.\n",
    "X_trn = XY_trn.as_matrix(columns=features)\n",
    "Y_trn = XY_trn.as_matrix(columns=['y'])\n",
    "dtrn = xgb.DMatrix(X_trn, label=Y_trn, feature_names=features)\n",
    "\n",
    "X_vld = XY_vld.as_matrix(columns=features)\n",
    "Y_vld = XY_vld.as_matrix(columns=['y'])\n",
    "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 모델을 훈련 데이터로 학습한다!\n",
    "watch_list = [(dtrn, 'train'), (dvld, 'eval')]\n",
    "model = xgb.train(param, dtrn, num_boost_round=1000, evals=watch_list, early_stopping_rounds=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 모델을 저장한다.\n",
    "import pickle \n",
    "#pickle 모듈: 텍스트 상태의 데이터가 아닌 파이썬 객체 자체를 파일로 저장\n",
    "#pickle.dump(객체, 파일) 로 저장하고\n",
    "#pickle.load(파일) 로 로딩\n",
    "\n",
    "pickle.dump(model, open(\"../model/xgb.baseline.pkl\", \"wb\"))\n",
    "best_ntree_limit = model.best_ntree_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차검증\n",
    "이번 경진대회의 평가척도인 MAP@7을 사용하여 성능 수준을 확인.\n",
    "(교차 검증 과정에서 경진대회에서 실제로 사용되는 평가 척도를 사용하는 것은 매우 중요)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터에서 얻을 수 있는 최고점 0.042663 < 1인 이유: 검증 데이터의 모든 고객이 신규 구매를 하지는 않았기 때문.\n",
    "\n",
    "예를 들어, 100명의 고객 중 10명만이 신규 구매 => 10명을 정확히 예측해도 10%의  MAP@7 점수를 받게 됨.\n",
    "\n",
    "따라서, 검증 데이터의 MAP@7 최고 점수를 감안하여 학습 모델의 성능을 평가해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP@7 평가 척도를 위한 준비작업이다.\n",
    "# 고객 식별 번호를 추출한다.\n",
    "vld = trn[trn['fecha_dato'] == vld_date] #훈련 데이터에서 검증 데이터 분리\n",
    "ncodpers_vld = vld.as_matrix(columns=['ncodpers']) #검증 데이터에서 고객식별번호 ncodpers \n",
    "\n",
    "# 검증 데이터에서 신규 구매를 구한다.\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    padd = prod + '_add'\n",
    "    vld[padd] = vld[prod] - vld[prev]   #신규 구매 여부 (이 값이 1이면 신규 구매한 것)\n",
    "add_vld = vld.as_matrix(columns=[prod + '_add' for prod in prods])\n",
    "add_vld_list = [list() for i in range(len(ncodpers_vld))]\n",
    "# 고객별 신규 구매 정답 값을 add_vld_list에 저장하고, 총 count를 count_vld에 저장한다.\n",
    "count_vld = 0\n",
    "for ncodper in range(len(ncodpers_vld)):\n",
    "    for prod in range(len(prods)):\n",
    "        if add_vld[ncodper, prod] > 0:\n",
    "            add_vld_list[ncodper].append(prod)\n",
    "            count_vld += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터에서 얻을 수 있는 MAP@7 최고점을 미리 구한다. (0.042663)\n",
    "print(mapk(add_vld_list, add_vld_list, 7, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터에 대한 예측 값을 구한다.\n",
    "X_vld = vld.as_matrix(columns=features)\n",
    "Y_vld = vld.as_matrix(columns=['y'])\n",
    "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
    "\n",
    "preds_vld = model.predict(dvld, ntree_limit=best_ntree_limit) #예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저번 달에 보유한 제품은 신규 구매가 불가하기 때문에, 확률값에서 미리 1을 빼준다\n",
    "preds_vld = preds_vld - vld.as_matrix(columns=[prod + '_prev' for prod in prods])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터 예측 상위 7개를 추출한다.\n",
    "result_vld = []\n",
    "for ncodper, pred in zip(ncodpers_vld, preds_vld):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    result_vld.append([ip for y,p,ip in y_prods])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터에서의 MAP@7 점수를 구한다. (0.036466)\n",
    "print(mapk(add_vld_list, result_vld, 7, 0.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터 최고 점수가 0.042663임을 감안한다면, Baseline 모델의 정확도는 0.036466/0.042663=0.85로 약 85% 수준."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 교차 검증에서 훈련 데이터의 일부를 도려내어 검증 데이터로 사용하였음.\n",
    "\n",
    "이번에는 테스트 데이터에 대해서 조금이라도 좋은 성능을 내기 위하여 훈련 데이터와 검증 데이터를 합친 전체 데이터에 대하여 모델 다시 학습.\n",
    "\n",
    "파라미터는 교차 검증을 통해 찾아낸 최적의 파라미터를 사용하되 트리의 개수를 늘어난 검증 데이터만큼 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 모델을 전체 훈련 데이터로 재학습한다!\n",
    "X_all = XY.as_matrix(columns=features)\n",
    "Y_all = XY.as_matrix(columns=['y'])\n",
    "dall = xgb.DMatrix(X_all, label=Y_all, feature_names=features)\n",
    "watch_list = [(dall, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트리 개수는 늘어난 데이터 양만큼 비례해서 증가한다.\n",
    "best_ntree_limit = int(best_ntree_limit * (len(XY_trn) + len(XY_vld)) / len(XY_trn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 모델 재학습!\n",
    "model = xgb.train(param, dall, num_boost_round=best_ntree_limit, evals=watch_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 중요도를 출력해본다. 예상하던 변수가 상위로 올라와 있는가?\n",
    "print(\"Feature importance:\")\n",
    "for kv in sorted([(k,v) for k,v in model.get_fscore().items()], key=lambda kv: kv[1], reverse=True):\n",
    "    print(kv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캐글 제출을 위하여 테스트 데이터에 대한 예측 값을 구한다.\n",
    "X_tst = tst.as_matrix(columns=features)\n",
    "dtst = xgb.DMatrix(X_tst, feature_names=features)\n",
    "preds_tst = model.predict(dtst, ntree_limit=best_ntree_limit)\n",
    "ncodpers_tst = tst.as_matrix(columns=['ncodpers'])\n",
    "preds_tst = preds_tst - tst.as_matrix(columns=[prod + '_prev' for prod in prods])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일을 생성한다.\n",
    "submit_file = open('../model/xgb.baseline.2015-06-28', 'w')\n",
    "submit_file.write('ncodpers,added_products\\n')\n",
    "for ncodper, pred in zip(ncodpers_tst, preds_tst):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    y_prods = [p for y,p,ip in y_prods]\n",
    "    submit_file.write('{},{}\\n'.format(int(ncodper), ' '.join(y_prods)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
